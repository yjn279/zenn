---
title: "TensorFlowのDataset.mapとDataset.shuffleでランダムな要素順を対応させる"
emoji: "⚙️"
type: "tech"
topics:
  - "python"
  - "tensorflow"
  - "ディープラーニング"
  - "機械学習"
published: true
published_at: "2022-12-18 22:05"
---

## はじめに
以前にTensorFlowのData APIでデータを効率的に流し込めると知り、Datasetを使い始めました。
ところが`Dataset.map`でどハマりし、今回4ヶ月越しに原因解明できたので、記事を書くことにしました。

:::message
この記事には、一部スマートでない（対処療法的な）解決策があります。
良い解決策がある方は、ぜひコメントに残していただけると嬉しいです。
:::


## 問題のコード
モデルに入力するデータとラベルとして学習するための出力用データがタプルになったデータセットを作成します。入力と出力はそれぞれ足すと10になる整数です。
```python
def func():
    """和が10になる値のタプルを返す関数"""
    n = random.randint(0, 10)
    return n, 10 - n

def map_func(data):
    """mapの中で任意のPythonを書くためのラッパー"""
    return tf.py_function(func=func, inp=[], Tout=[tf.int32, tf.int32])

def create_dataset():
    """入力用データセットと出力用データセットの作成"""
    dataset = tf.data.Dataset.range(5)
    dataset = dataset.shuffle(buffer_size=5)
    dataset = dataset.map(map_func)
    return dataset
```
上記は簡略化したコードなので、本来は必要ない`tf.py_function`を使用しています。
`inp`は`func`に渡す引数で、`Tout`は戻り値の型です。

`Dataset.map`では外部ライブラリなどを使おうとするとエラーが出たりするのですが、`tf.py_function`を使うことで実行速度と引き換えに自由にPythonを書くことができるようになります。実際のコードではここで外部ライブラリを使用していました。

それでは、作成したデータセットの中身を出力してみましょう。
```python
dataset = create_dataset()

# タプルのデータセットを入力と出力に分割
x = dataset.map(lambda x, y: x)
y = dataset.map(lambda x, y: y)

for x, y in zip(x, y):
    print(x, y)
```
データセットを分割して`zip`に入れるのは転置のためで、やっていることは`zip(*hoge)`と大体同じです。つまり、`[データ数（5）, データセット数（2）]`の2次元配列を`[データセット数（2）, データ数（5）]`に直しているだけです。

実行すると、このようになります。
```python
# tf.Tensor(2, shape=(), dtype=int32) tf.Tensor(6, shape=(), dtype=int32)
# tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)
# tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(7, shape=(), dtype=int32)
# tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)
# tf.Tensor(3, shape=(), dtype=int32) tf.Tensor(10, shape=(), dtype=int32)
```
あれ？入力と出力の対応関係が崩れてる…？
しかも出力に9が2つあるし。`2 + 6`も`0 + 9`も、足して10にはならないぞ、、

結果的には、`dataset.map` × `random`が組み合わさったことでハマっていました。そこに`dataset.shuffle`も加わったことでカオスな状態になり、解決までかなりの時間を要してしまいました。

## 原因 1
直接的な原因はこれです。2つの`dataset`を作成したことで、ランダム値を取得する際のseedが変わってしまったことが原因でした。
```python
x = dataset.map(lambda x, y: x)  # 1つ目のデータセット
y = dataset.map(lambda x, y: y)  # 2つ目のデータセット

for x, y in zip(x, y):
    print(x, y)
```

## 解決方法 1
データセットを1つにまとめることで解決できます。
```python
for data in dataset:
    print(data)
```
ただ今回は、実装の都合上この解決策は適用できませんでした（上記以外でも複数回データセットを呼び出す必要があった）。

なのでここからは、`dataset`を分けたい人のための解決方法を書いていきます。

## 解決方法 2
残念ながらここがスマートではないのですが、データごとにseedを固定することで解決できます。
```python
def func(seed=None):
    random.seed(seed.numpy())  # seedを設定
    n = random.randint(0, 5)
    return n, 10 - n

def map_func(data):
    # funcのseedとしてdata（整数）を渡す
    return tf.py_function(func=func, inp=[data], Tout=[tf.int32, tf.int32])
```
上記では各データに固有のseed（`tf.data.Dataset.range`で生成された整数）を渡すことで、呼び出しごとに実行結果が変わるのを防いでいます。

対処療法的でややダサいですが、汎用的ではあります。

## 原因 2
上記の修正で解決したかと思いきや、実はまだ別の問題が残っています。
修正したコードの実行結果はこのようになります。
```python
# tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(10, shape=(), dtype=int32)
# tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)
# tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(7, shape=(), dtype=int32)
# tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)
# tf.Tensor(3, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)
```
入力と出力の和は10になりませんが、順番を入れ替えることで10になっています。
完全にランダムになる問題は解決しましたが、対応関係が崩れている問題はまだ未解決のままですね。

これは、`dataset`の生成ごとに要素順がシャッフルされることが原因です。

## 解決方法 2（続き）
`dataset.shuffle`に`reshuffle_each_iteration=False`を渡すことで解決できます。
```python
def create_dataset():
    dataset = tf.data.Dataset.range(5)
    # 呼び出しのたびにシャッフルしない（最初だけシャッフルする）
    dataset = dataset.shuffle(buffer_size=5, reshuffle_each_iteration=False)
    dataset = dataset.map(map_func)
    return dataset
```
これで1回目の呼び出しでのみ要素順がシャッフルされ、2回目以降は同じ要素順が保たれます。

それでは、もう1度実行してみましょう！
```python
# tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)
# tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)
# tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(10, shape=(), dtype=int32)
# tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)
# tf.Tensor(3, shape=(), dtype=int32) tf.Tensor(7, shape=(), dtype=int32)
```
入力と出力の和が10になりました 🎉🎉🎉
ちゃんとシャッフルもされていますね。


## おわりに
今回は`Dataset.map` × `Dataset.shuffle` × `random`と3つの要素が絡み合った問題だったので、解決まで本当に時間がかかりました（というか実装ではもっと複雑だった）。

実際の入出力データは数値ではなく画像で、今回の数値は画像のトリミング位置にあたります。見ているのは画像なので、そもそも原因1が発生していると気付くまでにかなりの時間がかかってしまいました。

もはやなぜ今さら解決できたのか分かりませんが、急に思い付いたので解決できました。


## 参考
- [tf.data.Dataset  |  TensorFlow v2.11.0](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)
- [機械学習におけるランダムシードの研究 - Qiita](https://qiita.com/si1242/items/d2f9195c08826d87d6ad#tensorflow%E3%81%AE%E3%82%B7%E3%83%BC%E3%83%89%E5%9B%BA%E5%AE%9A)
- [Tensorflow tf.data.Dataset API, dataset unzip function? - Stack Overflow](https://stackoverflow.com/questions/53641920/tensorflow-tf-data-dataset-api-dataset-unzip-function)
- [Subsequent calls to tf.data.Dataset.map() with seeded random operation give same random sequences. · Issue #35090 · tensorflow/tensorflow](https://github.com/tensorflow/tensorflow/issues/35090)