---
title: "PandasのNaNに敗北した"
emoji: "🥲"
type: "tech"
topics:
  - "python"
  - "pandas"
published: true
published_at: "2025-06-06 12:00"
publication_name: "activecore"
---

## はじめに

こんにちは。普段はデータ分析の業務を担当しているwinnieです 🍯

最近、諸事情でPandasの `read_csv` で `dtype=str` を指定しながらCSVを読み込む作業をしていました。てっきり空のセルは空文字列になると思いきや、実際には `NaN` が紛れ込んでいて処理が止まってしまった……という悲しい体験談です。

この記事では、どういう事情で `dtype=str` を使わざるを得なかったのか、そしてなぜ空セルが `NaN` になってしまったのか、最後にどう解決したのかをまとめます。同じ罠にハマっている方の助けになりますように。

## なぜ `dtype=str` を使っていたのか

今回扱っていたCSVは、以下のような事情を抱えたファイルでした。

- 列ごとに数値・文字列・識別子が混在しており、型を自動推定させると余計なゼロ落ちや指数表記が発生する。
- 半角・全角や前後スペースの有無で意味が変わる列が存在し、読み込み直後に文字列として検証したかった。
- 後続の処理で「文字列であること」が前提の正規表現チェックが走る。

このため、強制的に全列を文字列として受け取るべく `read_csv(..., dtype=str)` を指定していました。ところが、ここで想定外の挙動に遭遇します。

## 空セルが `NaN` になる悲劇

空セルは空文字列として入ってくると思っていたのですが、実際に読み込んでみると `NaN` が混在していました。`dtype=str` を指定していても、Pandasは内部的に「欠損値として解釈できるトークン」を `NaN` に変換する挙動を持っています。

これにより、後続の正規表現チェックで `TypeError: expected string or bytes-like object` が発生し、処理が止まりました。データクレンジングの最中にこれが起きると、どの列でエラーが発生したのかを突き止めるだけでも一苦労です。

## `na_filter=False` で勝利する

ドキュメントを漁った結果、`read_csv` には `na_filter` というパラメーターが存在し、デフォルトは `True` になっていました。これを `False` に設定すると、空セルを `NaN` に変換しなくなり、晴れてすべてのセルを素直な文字列として受け取れるようになります。

```python
import pandas as pd

df = pd.read_csv(
    "./input.csv",
    dtype=str,
    na_filter=False,
)
```

こうすることで、空セルは空文字列のまま保持され、正規表現チェックも無事に通るようになりました。

なお、`na_filter=False` にすると `na_values` で指定した欠損値も検出されなくなるため、文字列として保持したい列だけを後から個別に変換する運用に切り替えました。

## 参考

- [pandas.read_csvで空文字をNaNにしない方法](https://note.nkmk.me/python-pandas-read-csv-tsv/#nancsv)【引用元】

## おわりに

`dtype=str` だけで何とかなると思い込んでいた私にとって、`na_filter` の存在は盲点でした。Pandasは便利な反面、デフォルト値の罠がたくさん潜んでいます。今回の学びは「デフォルトの挙動を疑い、必要なら明示的に無効化する」です。

同じように `NaN` に悩まされている方は、ぜひ `na_filter=False` を試してみてください。負けっぱなしで終わらずに済みますように！

